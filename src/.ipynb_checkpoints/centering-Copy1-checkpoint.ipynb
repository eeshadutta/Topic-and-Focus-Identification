{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk import pos_tag\n",
    "import spacy\n",
    "import numpy as np\n",
    "from nltk import grammar, parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John has been having a lot of trouble arranging his vacation.He cannot find anyone to take over his responsibilities.He called up Mike yesterday to work out a plan.Mike has annoyed him a lot recently.He called John on Friday last week.\n",
      "\n",
      "\n",
      "['John has been having a lot of trouble arranging his vacation', 'He cannot find anyone to take over his responsibilities', 'He called up Mike yesterday to work out a plan', 'Mike has annoyed him a lot recently', 'He called John on Friday last week']\n"
     ]
    }
   ],
   "source": [
    "filename = '../data/test1.txt'\n",
    "f = open(filename, \"r\")\n",
    "contents = f.read()\n",
    "print(contents)\n",
    "\n",
    "print(\"\\n\")\n",
    "utterances = []\n",
    "split_utterances = []\n",
    "sentences = contents.strip().split('.')\n",
    "for sentence in sentences:\n",
    "    if sentence != '':\n",
    "        utterances.append(sentence.strip())\n",
    "\n",
    "print(utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John', 'has', 'been', 'having', 'a', 'lot', 'of', 'trouble', 'arranging', 'his', 'vacation']\n",
      "['He', 'cannot', 'find', 'anyone', 'to', 'take', 'over', 'his', 'responsibilities']\n",
      "['He', 'called', 'up', 'Mike', 'yesterday', 'to', 'work', 'out', 'a', 'plan']\n",
      "['Mike', 'has', 'annoyed', 'him', 'a', 'lot', 'recently']\n",
      "['He', 'called', 'John', 'on', 'Friday', 'last', 'week']\n",
      "[[('John', 'NNP'), ('has', 'VBZ'), ('been', 'VBN'), ('having', 'VBG'), ('a', 'DT'), ('lot', 'NN'), ('of', 'IN'), ('trouble', 'NN'), ('arranging', 'VBG'), ('his', 'PRP$'), ('vacation', 'NN')], [('He', 'PRP'), ('cannot', 'VBZ'), ('find', 'VB'), ('anyone', 'NN'), ('to', 'TO'), ('take', 'VB'), ('over', 'RP'), ('his', 'PRP$'), ('responsibilities', 'NNS')], [('He', 'PRP'), ('called', 'VBD'), ('up', 'RP'), ('Mike', 'NNP'), ('yesterday', 'NN'), ('to', 'TO'), ('work', 'VB'), ('out', 'RP'), ('a', 'DT'), ('plan', 'NN')], [('Mike', 'NNP'), ('has', 'VBZ'), ('annoyed', 'VBN'), ('him', 'PRP'), ('a', 'DT'), ('lot', 'NN'), ('recently', 'RB')], [('He', 'PRP'), ('called', 'VBD'), ('John', 'NNP'), ('on', 'IN'), ('Friday', 'NNP'), ('last', 'JJ'), ('week', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "## pos tags\n",
    "pos_tags_utterances = []\n",
    "\n",
    "for utterance in split_utterances:\n",
    "    print(utterance)\n",
    "    pos_tags_utterances.append(pos_tag(utterance))\n",
    "    \n",
    "print(pos_tags_utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "John , John , nsubj , having\n",
      "a lot , lot , dobj , having\n",
      "trouble , trouble , pobj , of\n",
      "his vacation , vacation , dobj , arranging\n",
      "\n",
      "He , He , nsubj , find\n",
      "anyone , anyone , nsubj , take\n",
      "his responsibilities , responsibilities , dobj , take\n",
      "\n",
      "He , He , nsubj , called\n",
      "Mike , Mike , dobj , called\n",
      "a plan , plan , dobj , work\n",
      "\n",
      "Mike , Mike , nsubj , annoyed\n",
      "him , him , dobj , annoyed\n",
      "\n",
      "He , He , nsubj , called\n",
      "John , John , dobj , called\n",
      "Friday , Friday , pobj , on\n"
     ]
    }
   ],
   "source": [
    "for utterance in utterances:\n",
    "    processed_utterance = nlp(utterance)\n",
    "    \n",
    "    print()\n",
    "    for chunk in processed_utterance.noun_chunks:\n",
    "        print(chunk.text,\",\",chunk.root.text, \",\",chunk.root.dep_,\",\",chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('john', 'NNP'), ('lot', 'NN'), ('trouble', 'NN'), ('vacation', 'NN')]\n",
      "[('john', 'NNP'), ('anyone', 'NN'), ('responsibilities', 'NNS')]\n",
      "[('john', 'NNP'), ('mike', 'NNP'), ('yesterday', 'NN'), ('plan', 'NN')]\n",
      "[('mike', 'NNP'), ('lot', 'NN')]\n",
      "[('mike', 'NNP'), ('john', 'NNP'), ('friday', 'NNP'), ('week', 'NN')]\n",
      "['undefined', ('john', 'NNP'), ('john', 'NNP'), ('mike', 'NNP'), ('mike', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "topics_utterances = []\n",
    "focus_utterances = []\n",
    "\n",
    "total_utterances = len(utterances)\n",
    "\n",
    "Cb = [None] * total_utterances\n",
    "Cf = []\n",
    "for i in range(total_utterances):\n",
    "    Cf.append([])\n",
    "\n",
    "Cb[0] = \"undefined\"\n",
    "for i in range(total_utterances):\n",
    "    \n",
    "    for token in pos_tags_utterances[i]:\n",
    "        if \"NN\" in token[1]:\n",
    "            Cf[i].append((token[0].lower(), token[1]))\n",
    "        if \"PRP\" == token[1]:\n",
    "            if token[0].lower() == \"he\" or token[0].lower() == \"she\":\n",
    "                for pos in Cf[i-1]:\n",
    "                    if pos[1] == \"NNP\":\n",
    "                        if (pos[0].lower(), \"NNP\") not in Cf[i]:\n",
    "                            Cf[i].append((pos[0].lower(), \"NNP\"))\n",
    "                            break\n",
    "            elif token[0].lower() == \"it\":\n",
    "                for pos in Cf[i-1]:\n",
    "                    if pos[1] == \"NN\":\n",
    "                        if (pos[0].lower(), \"NN\") not in Cf[i]:\n",
    "                            Cf[i].append((pos[0].lower(), \"NN\"))\n",
    "                            break\n",
    "\n",
    "    if i != 0:\n",
    "        Cb[i] = Cf[i][0]\n",
    "\n",
    "        \n",
    "print(\"Centers\")        \n",
    "print(Cb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
