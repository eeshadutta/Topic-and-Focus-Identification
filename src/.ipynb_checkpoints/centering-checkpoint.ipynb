{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk import pos_tag\n",
    "import spacy\n",
    "import numpy as np\n",
    "from nltk import grammar, parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John went to his favorite music store to buy a piano.\\n', 'He was excited that he could finally buy a piano.He arrived just as the store was closing for the day.\\n', 'It was closing just as John arrived.']\n",
      "\n",
      "\n",
      "['John went to his favorite music store to buy a piano', 'He was excited that he could finally buy a piano', 'He arrived just as the store was closing for the day', 'It was closing just as John arrived']\n"
     ]
    }
   ],
   "source": [
    "filename = '../data/test.txt'\n",
    "f = open(filename, \"r\")\n",
    "contents = f.readlines()\n",
    "print(contents)\n",
    "\n",
    "print(\"\\n\")\n",
    "utterances = []\n",
    "split_utterances = []\n",
    "for line in contents:\n",
    "    sentences = line.strip().split('.')\n",
    "    for sentence in sentences:\n",
    "        if sentence != '':\n",
    "            utterances.append(sentence)\n",
    "            split_utterances.append(sentence.split(' '))\n",
    "\n",
    "print(utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('John', 'NNP'), ('went', 'VBD'), ('to', 'TO'), ('his', 'PRP$'), ('favorite', 'JJ'), ('music', 'NN'), ('store', 'NN'), ('to', 'TO'), ('buy', 'VB'), ('a', 'DT'), ('piano', 'NN')], [('He', 'PRP'), ('was', 'VBD'), ('excited', 'VBN'), ('that', 'IN'), ('he', 'PRP'), ('could', 'MD'), ('finally', 'RB'), ('buy', 'VB'), ('a', 'DT'), ('piano', 'NN')], [('He', 'PRP'), ('arrived', 'VBD'), ('just', 'RB'), ('as', 'IN'), ('the', 'DT'), ('store', 'NN'), ('was', 'VBD'), ('closing', 'VBG'), ('for', 'IN'), ('the', 'DT'), ('day', 'NN')], [('It', 'PRP'), ('was', 'VBD'), ('closing', 'VBG'), ('just', 'RB'), ('as', 'IN'), ('John', 'NNP'), ('arrived', 'VBD')]]\n"
     ]
    }
   ],
   "source": [
    "## pos tags\n",
    "pos_tags_utterances = []\n",
    "\n",
    "for utterance in split_utterances:\n",
    "    pos_tags_utterances.append(pos_tag(utterance))\n",
    "    \n",
    "print(pos_tags_utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "John , John , nsubj , went\n",
      "his favorite music store , store , pobj , to\n",
      "a piano , piano , dobj , buy\n",
      "\n",
      "He , He , nsubj , was\n",
      "he , he , nsubj , buy\n",
      "a piano , piano , dobj , buy\n",
      "\n",
      "He , He , nsubj , arrived\n",
      "the store , store , nsubj , closing\n",
      "the day , day , pobj , for\n",
      "\n",
      "It , It , nsubj , closing\n",
      "John , John , nsubj , arrived\n"
     ]
    }
   ],
   "source": [
    "for utterance in utterances:\n",
    "    processed_utterance = nlp(utterance)\n",
    "    \n",
    "    print()\n",
    "    for chunk in processed_utterance.noun_chunks:\n",
    "        print(chunk.text,\",\",chunk.root.text, \",\",chunk.root.dep_,\",\",chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9e5e5472e358>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m## Cb[i] is either Cp[i-1] among Cf[i]. This we have to decide.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m## Reading to be done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mCb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "topics_utterances = []\n",
    "focus_utterances = []\n",
    "\n",
    "total_utterances = len(utterances)\n",
    "\n",
    "Cb = [None] * total_utterances\n",
    "# Cf = [[]] * total_utterances\n",
    "# Cp = [None] * total_utterances\n",
    "\n",
    "Cf = []\n",
    "for i in range(total_utterances):\n",
    "    Cf.append([])\n",
    "\n",
    "Cb[0] = \"undefined\"\n",
    "for i in range(total_utterances):\n",
    "    \n",
    "#     if i != 0:\n",
    "#         Cf[i].append((Cp[i-1]))\n",
    "\n",
    "    \n",
    "    for token in pos_tags_utterances[i]:\n",
    "        if \"NN\" in token[1]:\n",
    "            Cf[i].append(token[0])\n",
    "    \n",
    "    ## Sort the Cf[i] in terms of score and assign the highest score one to Cp[i]\n",
    "#     Cp[i] = Cf[i][0]\n",
    "    \n",
    "    ## Cb[i] is either Cp[i-1] among Cf[i]. This we have to decide.\n",
    "    ## Reading to be done.\n",
    "    if i != 0:\n",
    "        Cb[i] = Cf[i-1][0]\n",
    "    \n",
    "for lis in Cf:\n",
    "    print(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
