{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk import pos_tag\n",
    "import spacy\n",
    "import numpy as np\n",
    "from nltk import grammar, parse\n",
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John has been having a lot of trouble arranging his vacation.He cannot find anyone to take over his responsibilities.He called up Mike yesterday to work out a plan.Mike has annoyed him a lot recently.He called John on Friday last week.\n",
      "\n",
      "\n",
      "['John has been having a lot of trouble arranging his vacation', 'He cannot find anyone to take over his responsibilities', 'He called up Mike yesterday to work out a plan', 'Mike has annoyed him a lot recently', 'He called John on Friday last week']\n"
     ]
    }
   ],
   "source": [
    "filename = '../data/test1.txt'\n",
    "f = open(filename, \"r\")\n",
    "contents = f.read()\n",
    "print(contents)\n",
    "\n",
    "print(\"\\n\")\n",
    "utterances = []\n",
    "split_utterances = []\n",
    "sentences = contents.strip().split('.')\n",
    "for sentence in sentences:\n",
    "    if sentence != '':\n",
    "        utterances.append(sentence.strip())\n",
    "\n",
    "print(utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John has been having a lot of trouble arranging his vacation\n",
      "He cannot find anyone to take over his responsibilities\n",
      "He called up Mike yesterday to work out a plan\n",
      "Mike has annoyed him a lot recently\n",
      "He called John on Friday last week\n",
      "[[('John', 'NNP'), ('has', 'VBZ'), ('been', 'VBN'), ('having', 'VBG'), ('a', 'DT'), ('lot', 'NN'), ('of', 'IN'), ('trouble', 'NN'), ('arranging', 'VBG'), ('his', 'PRP$'), ('vacation', 'NN')], [('He', 'PRP'), ('cannot', 'VBZ'), ('find', 'VB'), ('anyone', 'NN'), ('to', 'TO'), ('take', 'VB'), ('over', 'RP'), ('his', 'PRP$'), ('responsibilities', 'NNS')], [('He', 'PRP'), ('called', 'VBD'), ('up', 'RP'), ('Mike', 'NNP'), ('yesterday', 'NN'), ('to', 'TO'), ('work', 'VB'), ('out', 'RP'), ('a', 'DT'), ('plan', 'NN')], [('Mike', 'NNP'), ('has', 'VBZ'), ('annoyed', 'VBN'), ('him', 'PRP'), ('a', 'DT'), ('lot', 'NN'), ('recently', 'RB')], [('He', 'PRP'), ('called', 'VBD'), ('John', 'NNP'), ('on', 'IN'), ('Friday', 'NNP'), ('last', 'JJ'), ('week', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "## pos tags\n",
    "pos_tags_utterances = []\n",
    "\n",
    "for utterance in utterances:\n",
    "    print(utterance)\n",
    "    pos_tags_utterances.append(pos_tag(utterance.split(' ')))\n",
    "    \n",
    "print(pos_tags_utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "John , John , nsubj , having\n",
      "a lot , lot , dobj , having\n",
      "trouble , trouble , pobj , of\n",
      "his vacation , vacation , dobj , arranging\n"
     ]
    }
   ],
   "source": [
    "processed_utterance = nlp(utterances[0])\n",
    "init_topic = ''\n",
    "print()\n",
    "for chunk in processed_utterance.noun_chunks:\n",
    "    if chunk.root.dep_ == \"nsubj\":\n",
    "        init_topic = chunk.text\n",
    "    print(chunk.text,\",\",chunk.root.text, \",\",chunk.root.dep_,\",\",chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centers\n",
      "['undefined', ('john', 'NNP'), ('john', 'NNP'), ('mike', 'NNP'), ('mike', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "total_utterances = len(utterances)\n",
    "\n",
    "Cb = [None] * total_utterances\n",
    "\n",
    "Cf = []\n",
    "for i in range(total_utterances):\n",
    "    Cf.append([])\n",
    "\n",
    "Cb[0] = \"undefined\"\n",
    "for i in range(total_utterances):\n",
    "    \n",
    "    for token in pos_tags_utterances[i]:\n",
    "        if \"NN\" in token[1]:\n",
    "            Cf[i].append((token[0].lower(), token[1]))\n",
    "        if i!=0:\n",
    "            if \"PRP\" == token[1]:\n",
    "                if token[0].lower() == \"he\" or token[0].lower() == \"she\":\n",
    "                    for pos in Cf[i-1]:\n",
    "                        if pos[1] == \"NNP\":\n",
    "                            if (pos[0].lower(), \"NNP\") not in Cf[i]:\n",
    "                                Cf[i].append((pos[0].lower(), \"NNP\"))\n",
    "                                break\n",
    "                elif token[0].lower() == \"it\":\n",
    "                    for pos in Cf[i-1]:\n",
    "                        if pos[1] == \"NN\":\n",
    "                            if (pos[0].lower(), \"NN\") not in Cf[i]:\n",
    "                                Cf[i].append((pos[0].lower(), \"NN\"))\n",
    "                                break\n",
    "\n",
    "    if i != 0:\n",
    "        Cb[i] = Cf[i][0]\n",
    "\n",
    "        \n",
    "print(\"Centers\")        \n",
    "print(Cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John', 'John', 'John', 'Mike', 'Mike']\n"
     ]
    }
   ],
   "source": [
    "topics_utterances = []\n",
    "focus_utterances = []\n",
    "topics_utterances.append(init_topic)\n",
    "for tuple_val in Cb:\n",
    "    if tuple_val != \"undefined\":\n",
    "        if tuple_val[1] == \"NNP\":\n",
    "            topics_utterances.append(tuple_val[0].capitalize())\n",
    "        else:\n",
    "            topics_utterances.append(tuple_val[0])\n",
    "\n",
    "print(topics_utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics present in the discourse are:\n",
      "\n",
      "John\n",
      "Mike\n"
     ]
    }
   ],
   "source": [
    "topic_dict = {}\n",
    "for topic in topics_utterances:\n",
    "    if topic not in topic_dict.keys():\n",
    "        topic_dict[topic] = 1\n",
    "    else:\n",
    "        topic_dict[topic] += 1\n",
    "        \n",
    "k  = Counter(topic_dict)\n",
    "top_topics_num = len(topic_dict)/2\n",
    "top_topics_list = k.most_common(2)\n",
    "\n",
    "\n",
    "print(\"Topics present in the discourse are:\\n\")\n",
    "for topic in top_topics_list:\n",
    "    print(topic[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
